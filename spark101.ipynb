{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a07065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, expr, concat_ws, lit, regexp_extract, regexp_replace, asc, desc\n",
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean, round, month, year, quarter, date_format, when\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144902ee",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "    - The name of the column should be language\n",
    "    - View the schema of the dataframe\n",
    "    - Output the shape of the dataframe\n",
    "    - Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7658ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "programming_df = pd.DataFrame({'name': ['python', 'sql', 'regex', 'java', 'c++']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a019e697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name\n",
       "0  python\n",
       "1     sql\n",
       "2   regex\n",
       "3    java\n",
       "4     c++"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programming_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4a4273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 15:01:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e850e6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(programming_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f8bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8c1a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 rows 1 columns\n"
     ]
    }
   ],
   "source": [
    "df.count()\n",
    "print(df.count(),'rows', len(df.columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451e797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|python|\n",
      "|   sql|\n",
      "| regex|\n",
      "|  java|\n",
      "|   c++|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32893d4e",
   "metadata": {},
   "source": [
    "### 2. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "    a. Create 1 column of output that contains a message like the one below:\n",
    "        \n",
    "            - The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "        For each vehicle.\n",
    "\n",
    "    b. Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85353ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = data('mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49aaf99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[manufacturer: string, model: string, displ: double, year: bigint, cyl: bigint, trans: string, drv: string, cty: bigint, hwy: bigint, fl: string, class: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data('mpg')\n",
    "df = spark.createDataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efc883f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>displ</th>\n",
       "      <th>year</th>\n",
       "      <th>cyl</th>\n",
       "      <th>trans</th>\n",
       "      <th>drv</th>\n",
       "      <th>cty</th>\n",
       "      <th>hwy</th>\n",
       "      <th>fl</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m5)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m6)</td>\n",
       "      <td>f</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(av)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(s6)</td>\n",
       "      <td>f</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m6)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>manual(m5)</td>\n",
       "      <td>f</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>passat</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>auto(s6)</td>\n",
       "      <td>f</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>midsize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    manufacturer   model  displ  year  cyl       trans drv  cty  hwy fl  \\\n",
       "1           audi      a4    1.8  1999    4    auto(l5)   f   18   29  p   \n",
       "2           audi      a4    1.8  1999    4  manual(m5)   f   21   29  p   \n",
       "3           audi      a4    2.0  2008    4  manual(m6)   f   20   31  p   \n",
       "4           audi      a4    2.0  2008    4    auto(av)   f   21   30  p   \n",
       "5           audi      a4    2.8  1999    6    auto(l5)   f   16   26  p   \n",
       "..           ...     ...    ...   ...  ...         ...  ..  ...  ... ..   \n",
       "230   volkswagen  passat    2.0  2008    4    auto(s6)   f   19   28  p   \n",
       "231   volkswagen  passat    2.0  2008    4  manual(m6)   f   21   29  p   \n",
       "232   volkswagen  passat    2.8  1999    6    auto(l5)   f   16   26  p   \n",
       "233   volkswagen  passat    2.8  1999    6  manual(m5)   f   18   26  p   \n",
       "234   volkswagen  passat    3.6  2008    6    auto(s6)   f   17   26  p   \n",
       "\n",
       "       class  \n",
       "1    compact  \n",
       "2    compact  \n",
       "3    compact  \n",
       "4    compact  \n",
       "5    compact  \n",
       "..       ...  \n",
       "230  midsize  \n",
       "231  midsize  \n",
       "232  midsize  \n",
       "233  midsize  \n",
       "234  midsize  \n",
       "\n",
       "[234 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62805edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+\n",
      "|output                                                          |\n",
      "+----------------------------------------------------------------+\n",
      "|- The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|- The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|- The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|- The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|- The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|- The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|- The 2008 audi a4 has a 6 cylinder engine.                     |\n",
      "|- The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|- The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|- The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|- The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|- The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|- The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|- The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|- The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|- The 1999 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|- The 2008 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|- The 2008 audi a6 quattro has a 8 cylinder engine.             |\n",
      "|- The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "|- The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "+----------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg_df = df.withColumn(\n",
    "    \"output\",\n",
    "    concat_ws(\" \", \n",
    "              lit(\"- The\"), \n",
    "              df.year, \n",
    "              df.manufacturer, \n",
    "              df.model, \n",
    "              lit(\"has a\"), \n",
    "              df.cyl, \n",
    "              lit(\"cylinder engine.\")\n",
    "             )\n",
    ")\n",
    "\n",
    "\n",
    "mpg_df.select(mpg_df.output).show(truncate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b5e3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     trans|\n",
      "+----------+\n",
      "|  auto(l5)|\n",
      "|manual(m5)|\n",
      "|manual(m6)|\n",
      "|  auto(av)|\n",
      "|  auto(l5)|\n",
      "|manual(m5)|\n",
      "|  auto(av)|\n",
      "|manual(m5)|\n",
      "|  auto(l5)|\n",
      "|manual(m6)|\n",
      "|  auto(s6)|\n",
      "|  auto(l5)|\n",
      "|manual(m5)|\n",
      "|  auto(s6)|\n",
      "|manual(m6)|\n",
      "|  auto(l5)|\n",
      "|  auto(s6)|\n",
      "|  auto(s6)|\n",
      "|  auto(l4)|\n",
      "|  auto(l4)|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.trans).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d97a4b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|             model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|                a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|                a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|                a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|  auto(s6)|  4| 19| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|manual(m5)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|manual(m6)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a6 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 24|  p|midsize|\n",
      "|        audi|        a6 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|midsize|\n",
      "|        audi|        a6 quattro|  4.2|2008|  8|  auto(s6)|  4| 16| 23|  p|midsize|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 14| 20|  r|    suv|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 11| 15|  e|    suv|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9aeb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"trans\", regexp_replace(\"trans\", r\"\\(.*\\)\", \"\"))\n",
    "df = df.withColumn(\"trans\", regexp_replace(\"trans\", r\"auto.*\", \"auto\"))\n",
    "df = df.withColumn(\"trans\", regexp_replace(\"trans\", r\"manual.*\", \"manual\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b1585a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+------+---+---+---+---+-------+\n",
      "|manufacturer|             model|displ|year|cyl| trans|drv|cty|hwy| fl|  class|\n",
      "+------------+------------------+-----+----+---+------+---+---+---+---+-------+\n",
      "|        audi|                a4|  1.8|1999|  4|  auto|  f| 18| 29|  p|compact|\n",
      "|        audi|                a4|  1.8|1999|  4|manual|  f| 21| 29|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|manual|  f| 20| 31|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|  auto|  f| 21| 30|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|  auto|  f| 16| 26|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|manual|  f| 18| 26|  p|compact|\n",
      "|        audi|                a4|  3.1|2008|  6|  auto|  f| 18| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|manual|  4| 18| 26|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|  auto|  4| 16| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|manual|  4| 20| 28|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|  auto|  4| 19| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|  auto|  4| 15| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|manual|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|  auto|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|manual|  4| 15| 25|  p|compact|\n",
      "|        audi|        a6 quattro|  2.8|1999|  6|  auto|  4| 15| 24|  p|midsize|\n",
      "|        audi|        a6 quattro|  3.1|2008|  6|  auto|  4| 17| 25|  p|midsize|\n",
      "|        audi|        a6 quattro|  4.2|2008|  8|  auto|  4| 16| 23|  p|midsize|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto|  r| 14| 20|  r|    suv|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto|  r| 11| 15|  e|    suv|\n",
      "+------------+------------------+-----+----+---+------+---+---+---+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa09a7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "| trans|transmission|\n",
      "+------+------------+\n",
      "|  auto|        auto|\n",
      "|manual|      manual|\n",
      "|manual|      manual|\n",
      "|  auto|        auto|\n",
      "|  auto|        auto|\n",
      "|manual|      manual|\n",
      "|  auto|        auto|\n",
      "|manual|      manual|\n",
      "|  auto|        auto|\n",
      "|manual|      manual|\n",
      "|  auto|        auto|\n",
      "|  auto|        auto|\n",
      "|manual|      manual|\n",
      "|  auto|        auto|\n",
      "|manual|      manual|\n",
      "|  auto|        auto|\n",
      "|  auto|        auto|\n",
      "|  auto|        auto|\n",
      "|  auto|        auto|\n",
      "|  auto|        auto|\n",
      "+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"trans\", \n",
    "          regexp_replace(\"trans\", r\"\\(.*\\)\", \"\").alias('transmission')\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624f833",
   "metadata": {},
   "source": [
    "### 3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "    a. What percentage of observations are smokers?\n",
    "    b. Create a column that contains the tip percentage\n",
    "    c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b0af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = data('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c87e1154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_df = spark.createDataFrame(tips)\n",
    "tips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ba2e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c755d482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "|summary|        total_bill|               tip|   sex|smoker| day|  time|              size|\n",
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "|  count|               244|               244|   244|   244| 244|   244|               244|\n",
      "|   mean|19.785942622950813|2.9982786885245907|  null|  null|null|  null| 2.569672131147541|\n",
      "| stddev| 8.902411954856856| 1.383638189001182|  null|  null|null|  null|0.9510998047322344|\n",
      "|    min|              3.07|               1.0|Female|    No| Fri|Dinner|                 1|\n",
      "|    max|             50.81|              10.0|  Male|   Yes|Thur| Lunch|                 6|\n",
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e8b00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|\n",
      "+----------+----+------+------+----+------+----+\n",
      "|     38.01| 3.0|  Male|   Yes| Sat|Dinner|   4|\n",
      "|     11.24|1.76|  Male|   Yes| Sat|Dinner|   2|\n",
      "|     20.29|3.21|  Male|   Yes| Sat|Dinner|   2|\n",
      "|     13.81| 2.0|  Male|   Yes| Sat|Dinner|   2|\n",
      "|     11.02|1.98|  Male|   Yes| Sat|Dinner|   2|\n",
      "|     18.29|3.76|  Male|   Yes| Sat|Dinner|   4|\n",
      "|      3.07| 1.0|Female|   Yes| Sat|Dinner|   1|\n",
      "|     15.01|2.09|  Male|   Yes| Sat|Dinner|   2|\n",
      "|     26.86|3.14|Female|   Yes| Sat|Dinner|   2|\n",
      "|     25.28| 5.0|Female|   Yes| Sat|Dinner|   2|\n",
      "|     17.92|3.08|  Male|   Yes| Sat|Dinner|   2|\n",
      "|     19.44| 3.0|  Male|   Yes|Thur| Lunch|   2|\n",
      "|     32.68| 5.0|  Male|   Yes|Thur| Lunch|   2|\n",
      "|     28.97| 3.0|  Male|   Yes| Fri|Dinner|   2|\n",
      "|      5.75| 1.0|Female|   Yes| Fri|Dinner|   2|\n",
      "|     16.32| 4.3|Female|   Yes| Fri|Dinner|   2|\n",
      "|     40.17|4.73|  Male|   Yes| Fri|Dinner|   4|\n",
      "|     27.28| 4.0|  Male|   Yes| Fri|Dinner|   2|\n",
      "|     12.03| 1.5|  Male|   Yes| Fri|Dinner|   2|\n",
      "|     21.01| 3.0|  Male|   Yes| Fri|Dinner|   2|\n",
      "+----------+----+------+------+----+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips_df.filter(tips_df.smoker == 'Yes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d136438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of observations that are smokers is 38.11%\n"
     ]
    }
   ],
   "source": [
    "smoker_pct = tips_df.filter(tips_df.smoker == \"Yes\").count() / tips_df.count() * 100\n",
    "print(\"Percentage of observations that are smokers is {:.2f}%\".format(smoker_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d698df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+--------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tips_pct|\n",
      "+----------+----+------+------+---+------+----+--------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|    5.94|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|   16.05|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|   16.66|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|   13.98|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|   14.68|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|   18.62|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|   22.81|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|   11.61|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|   13.03|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|   21.85|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|   16.65|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|   14.18|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|   10.18|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|   16.28|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|   20.36|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|   18.16|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|   16.17|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|   22.77|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|   20.62|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|   16.22|\n",
      "+----------+----+------+------+---+------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips_df = tips_df.withColumn(\"tips_pct\", round((col(\"tip\")/col(\"total_bill\"))*100, 2))\n",
    "tips_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20abae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----------+\n",
      "|   sex|smoker|average_pct|\n",
      "+------+------+-----------+\n",
      "|  Male|    No|      16.07|\n",
      "|Female|    No|      15.69|\n",
      "|  Male|   Yes|      15.28|\n",
      "|Female|   Yes|      18.21|\n",
      "+------+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tips_df.groupBy(['sex','smoker']).agg(round(avg(\"tips_pct\"),2).alias('average_pct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a5ea1",
   "metadata": {},
   "source": [
    "### 4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa141608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abba8c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = data.seattle_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "311128e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "|2012-01-07|          0.0|     7.2|     2.8| 2.3|   rain|\n",
      "|2012-01-08|          0.0|    10.0|     2.8| 2.0|    sun|\n",
      "|2012-01-09|          4.3|     9.4|     5.0| 3.4|   rain|\n",
      "|2012-01-10|          1.0|     6.1|     0.6| 3.4|   rain|\n",
      "|2012-01-11|          0.0|     6.1|    -1.1| 5.1|    sun|\n",
      "|2012-01-12|          0.0|     6.1|    -1.7| 1.9|    sun|\n",
      "|2012-01-13|          0.0|     5.0|    -2.8| 1.3|    sun|\n",
      "|2012-01-14|          4.1|     4.4|     0.6| 5.3|   snow|\n",
      "|2012-01-15|          5.3|     1.1|    -3.3| 3.2|   snow|\n",
      "|2012-01-16|          2.5|     1.7|    -2.8| 5.0|   snow|\n",
      "|2012-01-17|          8.1|     3.3|     0.0| 5.6|   snow|\n",
      "|2012-01-18|         19.8|     0.0|    -2.8| 5.0|   snow|\n",
      "|2012-01-19|         15.2|    -1.1|    -2.8| 1.6|   snow|\n",
      "|2012-01-20|         13.5|     7.2|    -1.1| 2.3|   snow|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "seattle_df = spark.createDataFrame(weather)\n",
    "seattle_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13992073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----+-------+----------+----------+\n",
      "|      date|precipitation|wind|weather|temp_max_f|temp_min_f|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "|2012-01-01|          0.0| 4.7|drizzle|     55.04|      41.0|\n",
      "|2012-01-02|         10.9| 4.5|   rain|     51.08|     37.04|\n",
      "|2012-01-03|          0.8| 2.3|   rain|     53.06|     44.96|\n",
      "|2012-01-04|         20.3| 4.7|   rain|     53.96|     42.08|\n",
      "|2012-01-05|          1.3| 6.1|   rain|     48.02|     37.04|\n",
      "|2012-01-06|          2.5| 2.2|   rain|     39.92|     35.96|\n",
      "|2012-01-07|          0.0| 2.3|   rain|     44.96|     37.04|\n",
      "|2012-01-08|          0.0| 2.0|    sun|      50.0|     37.04|\n",
      "|2012-01-09|          4.3| 3.4|   rain|     48.92|      41.0|\n",
      "|2012-01-10|          1.0| 3.4|   rain|     42.98|     33.08|\n",
      "|2012-01-11|          0.0| 5.1|    sun|     42.98|     30.02|\n",
      "|2012-01-12|          0.0| 1.9|    sun|     42.98|     28.94|\n",
      "|2012-01-13|          0.0| 1.3|    sun|      41.0|     26.96|\n",
      "|2012-01-14|          4.1| 5.3|   snow|     39.92|     33.08|\n",
      "|2012-01-15|          5.3| 3.2|   snow|     33.98|     26.06|\n",
      "|2012-01-16|          2.5| 5.0|   snow|     35.06|     26.96|\n",
      "|2012-01-17|          8.1| 5.6|   snow|     37.94|      32.0|\n",
      "|2012-01-18|         19.8| 5.0|   snow|      32.0|     26.96|\n",
      "|2012-01-19|         15.2| 1.6|   snow|     30.02|     26.96|\n",
      "|2012-01-20|         13.5| 2.3|   snow|     44.96|     30.02|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seattle_df = seattle_df.withColumn(\"temp_max_f\", round(col(\"temp_max\") * 9/5 + 32, 2))\\\n",
    "                     .withColumn(\"temp_min_f\", round(col(\"temp_min\") * 9/5 + 32, 2))\\\n",
    "                     .drop(\"temp_max\", \"temp_min\")\n",
    "\n",
    "seattle_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f96ac006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+---+\n",
      "|      date|year|month|day|\n",
      "+----------+----+-----+---+\n",
      "|2012-01-01|2012|   01| 01|\n",
      "|2012-01-02|2012|   01| 02|\n",
      "|2012-01-03|2012|   01| 03|\n",
      "|2012-01-04|2012|   01| 04|\n",
      "|2012-01-05|2012|   01| 05|\n",
      "|2012-01-06|2012|   01| 06|\n",
      "|2012-01-07|2012|   01| 07|\n",
      "|2012-01-08|2012|   01| 08|\n",
      "|2012-01-09|2012|   01| 09|\n",
      "|2012-01-10|2012|   01| 10|\n",
      "|2012-01-11|2012|   01| 11|\n",
      "|2012-01-12|2012|   01| 12|\n",
      "|2012-01-13|2012|   01| 13|\n",
      "|2012-01-14|2012|   01| 14|\n",
      "|2012-01-15|2012|   01| 15|\n",
      "|2012-01-16|2012|   01| 16|\n",
      "|2012-01-17|2012|   01| 17|\n",
      "|2012-01-18|2012|   01| 18|\n",
      "|2012-01-19|2012|   01| 19|\n",
      "|2012-01-20|2012|   01| 20|\n",
      "+----------+----+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seattle_df.select(\"date\",\n",
    "                  regexp_extract(\"date\", r\"^\\d{4}\", 0).alias(\"year\"),\n",
    "                  regexp_extract(\"date\", r\"-(\\d{2})-\", 1).alias(\"month\"),\n",
    "                  regexp_extract(\"date\", r\"-(\\d{2})$\", 1).alias(\"day\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "333ad18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|month|total_rainfall|\n",
      "+-----+--------------+\n",
      "|   11|          5.35|\n",
      "|   12|          5.02|\n",
      "|    3|          4.89|\n",
      "+-----+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seattle_df.withColumn(\"month\", month(\"date\"))\\\n",
    "    .groupBy(\"month\")\\\n",
    "    .agg(round(mean(\"precipitation\"), 2).alias(\"total_rainfall\"))\\\n",
    "    .sort(desc(\"total_rainfall\"))\\\n",
    "    .show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f0115c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|weather|\n",
      "+-------+\n",
      "|drizzle|\n",
      "|   rain|\n",
      "|    sun|\n",
      "|   snow|\n",
      "|    fog|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seattle_df.select('weather').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "185e707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|year|total_wind|\n",
      "+----+----------+\n",
      "|2012|       3.4|\n",
      "|2014|      3.39|\n",
      "|2015|      3.16|\n",
      "|2013|      3.02|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seattle_df.withColumn(\"year\", year(\"date\"))\\\n",
    "    .groupBy(\"year\")\\\n",
    "    .agg(round(mean(\"wind\"), 2).alias(\"total_wind\"))\\\n",
    "    .sort(desc(\"total_wind\"))\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "092c6ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|weather|freq_weather|\n",
      "+-------+------------+\n",
      "|    fog|          38|\n",
      "|   rain|          35|\n",
      "|    sun|          33|\n",
      "|drizzle|          10|\n",
      "|   snow|           8|\n",
      "+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seattle_df.filter(month(\"date\") == 1)\\\n",
    "    .groupBy(\"weather\")\\\n",
    "    .agg(count(\"weather\").alias(\"freq_weather\"))\\\n",
    "    .sort(desc(\"freq_weather\"))\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e5ede",
   "metadata": {},
   "source": [
    "#### Question 4 continued\n",
    "\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fbb84ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----+-------+----------+----------+\n",
      "|      date|precipitation|wind|weather|temp_max_f|temp_min_f|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "|2012-07-04|          0.0| 3.8|    sun|     69.08|     48.92|\n",
      "|2012-07-06|          0.0| 2.1|    sun|      77.0|     51.98|\n",
      "|2012-07-07|          0.0| 3.8|    sun|     80.06|     55.04|\n",
      "|2012-07-17|          0.0| 2.6|    sun|     71.06|      59.0|\n",
      "|2012-07-18|          0.0| 2.9|    sun|     69.98|     57.92|\n",
      "|2012-07-19|          0.0| 2.2|    sun|      77.0|     57.92|\n",
      "|2012-07-21|          0.0| 2.3|    sun|     75.02|     57.02|\n",
      "|2012-07-24|          0.0| 4.3|    sun|     73.94|     53.96|\n",
      "|2012-07-25|          0.0| 2.6|    sun|     80.06|     55.04|\n",
      "|2012-07-29|          0.0| 2.0|    sun|     73.04|      59.0|\n",
      "|2012-07-30|          0.0| 3.0|    sun|     66.92|     55.94|\n",
      "|2012-07-31|          0.0| 2.8|    sun|     73.04|     57.02|\n",
      "|2013-07-01|          0.0| 2.3|    sun|     89.06|     64.94|\n",
      "|2013-07-02|          0.0| 3.0|    sun|     82.94|     60.08|\n",
      "|2013-07-03|          0.0| 3.2|    sun|     78.98|     62.06|\n",
      "|2013-07-05|          0.0| 2.6|    sun|     73.94|     57.02|\n",
      "|2013-07-06|          0.0| 2.2|    sun|     78.98|     55.94|\n",
      "|2013-07-07|          0.0| 2.9|    sun|     75.02|     57.02|\n",
      "|2013-07-08|          0.0| 2.8|    sun|     80.06|     55.94|\n",
      "|2013-07-09|          0.0| 2.5|    sun|      86.0|      59.0|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seattle_df.filter(month('date') == '07').where(col('weather') == 'sun').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d87020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only sunny days in July 2013 and 2014\n",
    "sunny_days_july_2013_2014 = seattle_df.filter((month('date') == '07') & (year('date').isin(['2013', '2014'])) & (col('weather') == 'sun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dadbb4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----+-------+----------+----------+\n",
      "|      date|precipitation|wind|weather|temp_max_f|temp_min_f|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "|2013-07-01|          0.0| 2.3|    sun|     89.06|     64.94|\n",
      "|2013-07-02|          0.0| 3.0|    sun|     82.94|     60.08|\n",
      "|2013-07-03|          0.0| 3.2|    sun|     78.98|     62.06|\n",
      "|2013-07-05|          0.0| 2.6|    sun|     73.94|     57.02|\n",
      "|2013-07-06|          0.0| 2.2|    sun|     78.98|     55.94|\n",
      "|2013-07-07|          0.0| 2.9|    sun|     75.02|     57.02|\n",
      "|2013-07-08|          0.0| 2.8|    sun|     80.06|     55.94|\n",
      "|2013-07-09|          0.0| 2.5|    sun|      86.0|      59.0|\n",
      "|2013-07-10|          0.0| 2.6|    sun|     71.96|     57.02|\n",
      "|2013-07-11|          0.0| 3.0|    sun|     73.04|     53.96|\n",
      "|2013-07-12|          0.0| 2.2|    sun|     66.92|     55.94|\n",
      "|2013-07-13|          0.0| 3.1|    sun|     78.98|     51.98|\n",
      "|2013-07-14|          0.0| 3.0|    sun|     82.04|     55.04|\n",
      "|2013-07-15|          0.0| 4.6|    sun|     82.04|     57.92|\n",
      "|2013-07-16|          0.0| 4.1|    sun|     87.98|     64.94|\n",
      "|2013-07-18|          0.0| 2.0|    sun|     78.98|     57.02|\n",
      "|2013-07-19|          0.0| 1.9|    sun|     82.04|     55.94|\n",
      "|2013-07-20|          0.0| 2.0|    sun|      77.0|     55.94|\n",
      "|2013-07-21|          0.0| 2.3|    sun|     75.02|     55.04|\n",
      "|2013-07-23|          0.0| 3.0|    sun|     87.98|     57.02|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sunny_days_july_2013_2014.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7468fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average high temperature on sunny days in July 2013 and 2014 is 80.29 F\n",
      "Average low temperature on sunny days in July 2013 and 2014 is 57.53 F\n"
     ]
    }
   ],
   "source": [
    "# Compute the average high and low temperature for sunny days in July 2013 and 2014\n",
    "avg_temp_max_f = sunny_days_july_2013_2014.agg(avg(col('temp_max_f'))).collect()[0][0]\n",
    "avg_temp_min_f = sunny_days_july_2013_2014.agg(avg(col('temp_min_f'))).collect()[0][0]\n",
    "\n",
    "#print(avg_temp_max_f)\n",
    "#print(avg_temp_min_f)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average high temperature on sunny days in July 2013 and 2014 is {avg_temp_max_f:.2f} F\")\n",
    "print(f\"Average low temperature on sunny days in July 2013 and 2014 is {avg_temp_min_f:.2f} F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a37d1cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of days that were rainy in Q3 of 2015: 2.17%\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to include only days in Q3 of 2015\n",
    "q3_2015 = seattle_df.filter((year('date') == '2015') & (quarter('date') == '3'))\n",
    "\n",
    "# Count the number of rainy days in Q3 of 2015\n",
    "rainy_days_q3_2015 = q3_2015.filter(col('weather') == 'rain').count()\n",
    "\n",
    "# Count the total number of days in Q3 of 2015\n",
    "total_days_q3_2015 = q3_2015.count()\n",
    "\n",
    "# Compute the percentage of days that were rainy in Q3 of 2015\n",
    "percentage_rainy_q3_2015 = (rainy_days_q3_2015 / total_days_q3_2015) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Percentage of days that were rainy in Q3 of 2015: {percentage_rainy_q3_2015:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ba634fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Column '`sum(count)`' does not exist. Did you mean one of the following? [sun, snow, fog, rain, drizzle, year];\n'Project [year#1699, (CASE WHEN (rain#1702L > cast(0 as bigint)) THEN rain#1702L ELSE cast(0 as bigint) END / 'sum(count)) AS percentage_rainy_days#1711]\n+- Project [coalesce(year#1638, cast(0.0 as int)) AS year#1699, coalesce(drizzle#1672L, cast(0.0 as bigint)) AS drizzle#1700L, coalesce(fog#1673L, cast(0.0 as bigint)) AS fog#1701L, coalesce(rain#1674L, cast(0.0 as bigint)) AS rain#1702L, coalesce(snow#1675L, cast(0.0 as bigint)) AS snow#1703L, coalesce(sun#1676L, cast(0.0 as bigint)) AS sun#1704L]\n   +- Project [year#1638, __pivot_count(count) AS count AS `count(count) AS count`#1671[0] AS drizzle#1672L, __pivot_count(count) AS count AS `count(count) AS count`#1671[1] AS fog#1673L, __pivot_count(count) AS count AS `count(count) AS count`#1671[2] AS rain#1674L, __pivot_count(count) AS count AS `count(count) AS count`#1671[3] AS snow#1675L, __pivot_count(count) AS count AS `count(count) AS count`#1671[4] AS sun#1676L]\n      +- Aggregate [year#1638], [year#1638, pivotfirst(weather#1057, count(count) AS count#1659L, drizzle, fog, rain, snow, sun, 0, 0) AS __pivot_count(count) AS count AS `count(count) AS count`#1671]\n         +- Aggregate [year#1638, weather#1057], [year#1638, weather#1057, count(count#1646L) AS count(count) AS count#1659L]\n            +- Aggregate [year(cast(date#1052 as date)), weather#1057], [year(cast(date#1052 as date)) AS year#1638, weather#1057, count(1) AS count#1646L]\n               +- Project [date#1052, precipitation#1053, wind#1056, weather#1057, temp_max_f#1089, temp_min_f#1097]\n                  +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, temp_max_f#1089, round((((temp_min#1055 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_min_f#1097]\n                     +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, round((((temp_max#1054 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_max_f#1089]\n                        +- LogicalRDD [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m yearly_weather_counts_pivot \u001b[38;5;241m=\u001b[39m yearly_weather_counts\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m                                                   \u001b[38;5;241m.\u001b[39mpivot(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m      8\u001b[0m                                                   \u001b[38;5;241m.\u001b[39magg(count(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)) \\\n\u001b[1;32m      9\u001b[0m                                                   \u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute the percentage of rainy days for each year\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m yearly_rainy_perc \u001b[38;5;241m=\u001b[39m \u001b[43myearly_weather_counts_pivot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43motherwise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum(count)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpercentage_rainy_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Print the result\u001b[39;00m\n\u001b[1;32m     17\u001b[0m yearly_rainy_perc\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2023\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \n\u001b[1;32m   2005\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2023\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Column '`sum(count)`' does not exist. Did you mean one of the following? [sun, snow, fog, rain, drizzle, year];\n'Project [year#1699, (CASE WHEN (rain#1702L > cast(0 as bigint)) THEN rain#1702L ELSE cast(0 as bigint) END / 'sum(count)) AS percentage_rainy_days#1711]\n+- Project [coalesce(year#1638, cast(0.0 as int)) AS year#1699, coalesce(drizzle#1672L, cast(0.0 as bigint)) AS drizzle#1700L, coalesce(fog#1673L, cast(0.0 as bigint)) AS fog#1701L, coalesce(rain#1674L, cast(0.0 as bigint)) AS rain#1702L, coalesce(snow#1675L, cast(0.0 as bigint)) AS snow#1703L, coalesce(sun#1676L, cast(0.0 as bigint)) AS sun#1704L]\n   +- Project [year#1638, __pivot_count(count) AS count AS `count(count) AS count`#1671[0] AS drizzle#1672L, __pivot_count(count) AS count AS `count(count) AS count`#1671[1] AS fog#1673L, __pivot_count(count) AS count AS `count(count) AS count`#1671[2] AS rain#1674L, __pivot_count(count) AS count AS `count(count) AS count`#1671[3] AS snow#1675L, __pivot_count(count) AS count AS `count(count) AS count`#1671[4] AS sun#1676L]\n      +- Aggregate [year#1638], [year#1638, pivotfirst(weather#1057, count(count) AS count#1659L, drizzle, fog, rain, snow, sun, 0, 0) AS __pivot_count(count) AS count AS `count(count) AS count`#1671]\n         +- Aggregate [year#1638, weather#1057], [year#1638, weather#1057, count(count#1646L) AS count(count) AS count#1659L]\n            +- Aggregate [year(cast(date#1052 as date)), weather#1057], [year(cast(date#1052 as date)) AS year#1638, weather#1057, count(1) AS count#1646L]\n               +- Project [date#1052, precipitation#1053, wind#1056, weather#1057, temp_max_f#1089, temp_min_f#1097]\n                  +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, temp_max_f#1089, round((((temp_min#1055 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_min_f#1097]\n                     +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, round((((temp_max#1054 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_max_f#1089]\n                        +- LogicalRDD [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057], false\n"
     ]
    }
   ],
   "source": [
    "# Group the DataFrame by year and weather, and count the number of days for each group\n",
    "yearly_weather_counts = seattle_df.groupBy(year('date').alias('year'), 'weather') \\\n",
    "                                  .agg(count('*').alias('count'))\n",
    "\n",
    "# Pivot the DataFrame so that each weather type becomes a column\n",
    "yearly_weather_counts_pivot = yearly_weather_counts.groupBy('year') \\\n",
    "                                                  .pivot('weather') \\\n",
    "                                                  .agg(count('count').alias('count')) \\\n",
    "                                                  .fillna(0)\n",
    "\n",
    "# Compute the percentage of rainy days for each year\n",
    "yearly_rainy_perc = yearly_weather_counts_pivot.select('year', (when(col('rain') > 0, col('rain')) \\\n",
    "                                                               .otherwise(0) / col('sum(count)')) \\\n",
    "                                                              .alias('percentage_rainy_days'))\n",
    "\n",
    "# Print the result\n",
    "yearly_rainy_perc.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c7a5f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column 'count' does not exist. Did you mean one of the following? [sun, fog, rain, snow, year, drizzle];\n'Aggregate [year#1773, (CASE WHEN (rain#1776L > cast(0 as bigint)) THEN rain#1776L ELSE cast(0 as bigint) END / sum('count)) AS percentage_rainy_days#1786]\n+- Project [coalesce(year#1712, cast(0.0 as int)) AS year#1773, coalesce(drizzle#1746L, cast(0.0 as bigint)) AS drizzle#1774L, coalesce(fog#1747L, cast(0.0 as bigint)) AS fog#1775L, coalesce(rain#1748L, cast(0.0 as bigint)) AS rain#1776L, coalesce(snow#1749L, cast(0.0 as bigint)) AS snow#1777L, coalesce(sun#1750L, cast(0.0 as bigint)) AS sun#1778L]\n   +- Project [year#1712, __pivot_count(count) AS count AS `count(count) AS count`#1745[0] AS drizzle#1746L, __pivot_count(count) AS count AS `count(count) AS count`#1745[1] AS fog#1747L, __pivot_count(count) AS count AS `count(count) AS count`#1745[2] AS rain#1748L, __pivot_count(count) AS count AS `count(count) AS count`#1745[3] AS snow#1749L, __pivot_count(count) AS count AS `count(count) AS count`#1745[4] AS sun#1750L]\n      +- Aggregate [year#1712], [year#1712, pivotfirst(weather#1057, count(count) AS count#1733L, drizzle, fog, rain, snow, sun, 0, 0) AS __pivot_count(count) AS count AS `count(count) AS count`#1745]\n         +- Aggregate [year#1712, weather#1057], [year#1712, weather#1057, count(count#1720L) AS count(count) AS count#1733L]\n            +- Aggregate [year(cast(date#1052 as date)), weather#1057], [year(cast(date#1052 as date)) AS year#1712, weather#1057, count(date#1052) AS count#1720L]\n               +- Project [date#1052, precipitation#1053, wind#1056, weather#1057, temp_max_f#1089, temp_min_f#1097]\n                  +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, temp_max_f#1089, round((((temp_min#1055 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_min_f#1097]\n                     +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, round((((temp_max#1054 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_max_f#1089]\n                        +- LogicalRDD [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m yearly_weather_counts_pivot \u001b[38;5;241m=\u001b[39m yearly_weather_counts\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m                                                   \u001b[38;5;241m.\u001b[39mpivot(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m                                                   \u001b[38;5;241m.\u001b[39magg(count(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)) \\\n\u001b[1;32m      8\u001b[0m                                                   \u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Compute the percentage of rainy days for each year\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m yearly_rainy_perc \u001b[38;5;241m=\u001b[39m \u001b[43myearly_weather_counts_pivot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43motherwise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpercentage_rainy_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the result\u001b[39;00m\n\u001b[1;32m     16\u001b[0m yearly_rainy_perc\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2023\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \n\u001b[1;32m   2005\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2023\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Column 'count' does not exist. Did you mean one of the following? [sun, fog, rain, snow, year, drizzle];\n'Aggregate [year#1773, (CASE WHEN (rain#1776L > cast(0 as bigint)) THEN rain#1776L ELSE cast(0 as bigint) END / sum('count)) AS percentage_rainy_days#1786]\n+- Project [coalesce(year#1712, cast(0.0 as int)) AS year#1773, coalesce(drizzle#1746L, cast(0.0 as bigint)) AS drizzle#1774L, coalesce(fog#1747L, cast(0.0 as bigint)) AS fog#1775L, coalesce(rain#1748L, cast(0.0 as bigint)) AS rain#1776L, coalesce(snow#1749L, cast(0.0 as bigint)) AS snow#1777L, coalesce(sun#1750L, cast(0.0 as bigint)) AS sun#1778L]\n   +- Project [year#1712, __pivot_count(count) AS count AS `count(count) AS count`#1745[0] AS drizzle#1746L, __pivot_count(count) AS count AS `count(count) AS count`#1745[1] AS fog#1747L, __pivot_count(count) AS count AS `count(count) AS count`#1745[2] AS rain#1748L, __pivot_count(count) AS count AS `count(count) AS count`#1745[3] AS snow#1749L, __pivot_count(count) AS count AS `count(count) AS count`#1745[4] AS sun#1750L]\n      +- Aggregate [year#1712], [year#1712, pivotfirst(weather#1057, count(count) AS count#1733L, drizzle, fog, rain, snow, sun, 0, 0) AS __pivot_count(count) AS count AS `count(count) AS count`#1745]\n         +- Aggregate [year#1712, weather#1057], [year#1712, weather#1057, count(count#1720L) AS count(count) AS count#1733L]\n            +- Aggregate [year(cast(date#1052 as date)), weather#1057], [year(cast(date#1052 as date)) AS year#1712, weather#1057, count(date#1052) AS count#1720L]\n               +- Project [date#1052, precipitation#1053, wind#1056, weather#1057, temp_max_f#1089, temp_min_f#1097]\n                  +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, temp_max_f#1089, round((((temp_min#1055 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_min_f#1097]\n                     +- Project [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057, round((((temp_max#1054 * cast(9 as double)) / cast(5 as double)) + cast(32 as double)), 2) AS temp_max_f#1089]\n                        +- LogicalRDD [date#1052, precipitation#1053, temp_max#1054, temp_min#1055, wind#1056, weather#1057], false\n"
     ]
    }
   ],
   "source": [
    "# Pivot the weather column and compute the count of each weather type for each year\n",
    "yearly_weather_counts = seattle_df.groupBy(year('date').alias('year'), 'weather') \\\n",
    "                                  .agg(count('date').alias('count'))\n",
    "\n",
    "yearly_weather_counts_pivot = yearly_weather_counts.groupBy('year') \\\n",
    "                                                  .pivot('weather') \\\n",
    "                                                  .agg(count('count').alias('count')) \\\n",
    "                                                  .fillna(0)\n",
    "\n",
    "# Compute the percentage of rainy days for each year\n",
    "yearly_rainy_perc = yearly_weather_counts_pivot.select('year', (when(col('rain') > 0, col('rain')) \\\n",
    "                                                                .otherwise(0) / sum('count')) \\\n",
    "                                                               .alias('percentage_rainy_days'))\n",
    "\n",
    "# Print the result\n",
    "yearly_rainy_perc.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa0c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
